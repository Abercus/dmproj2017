{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for finding duplicate data\n",
    "\n",
    "TODO:\n",
    "\n",
    "1) For each broker separately - look how much decrease...\n",
    "\n",
    "2) Phase 2...\n",
    "\n",
    "Following notebook is to find out how much duplicate requests.\n",
    "\n",
    "\n",
    "With each request_uuid we have parameters - pickup_timetamp, return_timestamp, broker_contract, driver_age the same..\n",
    "\n",
    "Duplicates can be spotted as following:\n",
    "\n",
    "1) Same request_id\n",
    "\n",
    "2) Different request_id, but close time, same broker and same other parameters (age, source...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (14, 6)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2997586, 9)\n"
     ]
    }
   ],
   "source": [
    "# Read data..\n",
    "\n",
    "fields = [\"timestamp\", \"pickup_timestamp\", \"return_timestamp\", \"broker_contract_id\", \"driver_age\", \n",
    "          \"request_uuid\", \"source_country_region_id\", \"pickup_desk_id\", \"return_desk_id\"]\n",
    "df = pd.read_csv(\"rate_quote.csv\", skipinitialspace=True, usecols=fields)\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 3)\n",
      "Contract_ID       int64\n",
      "Contract_name    object\n",
      "Broker name      object\n",
      "dtype: object\n",
      "timestamp                   datetime64[ns]\n",
      "pickup_desk_id                       int64\n",
      "return_desk_id                       int64\n",
      "pickup_timestamp            datetime64[ns]\n",
      "return_timestamp            datetime64[ns]\n",
      "broker_contract_id                   int64\n",
      "source_country_region_id             int64\n",
      "driver_age                           int64\n",
      "request_uuid                        object\n",
      "Contract_name                       object\n",
      "Broker_name                         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df['timestamp'])\n",
    "df[\"pickup_timestamp\"] = pd.to_datetime(df['pickup_timestamp'])\n",
    "df[\"return_timestamp\"] = pd.to_datetime(df['return_timestamp'])\n",
    "\n",
    "\n",
    "# Merge with broker contract name\n",
    "fields = [\"Contract_ID\", \"Contract_name\", \"Broker name\"]\n",
    "contract_df = pd.read_csv(\"broker_contracts.csv\", skipinitialspace=True, usecols=fields)\n",
    "contract_df[\"Broker name\"] = contract_df[\"Broker name\"].astype(str)\n",
    "contract_df[\"Contract_name\"] = contract_df[\"Contract_name\"].astype(str)\n",
    "# This holds contract names and which broker name corresponds to each contract id..\n",
    "#contract_df = contract_df.set_index(\"Contract_ID\")\n",
    "\n",
    "print(contract_df.shape)\n",
    "print(contract_df.dtypes)\n",
    "\n",
    "\n",
    "contract_df.columns = [\"broker_contract_id\", \"Contract_name\", \"Broker_name\"]\n",
    "    \n",
    "#print(df)\n",
    "    \n",
    "    \n",
    "merged_requests = pd.merge(df, contract_df, on=[\"broker_contract_id\"])\n",
    "\n",
    "print(merged_requests.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 - Removing duplicates using request_uuid\n",
    "\n",
    "1) Load in all data\n",
    "\n",
    "2) Group data by request_uuid, for each find minimal timestamp and set it as aggregate row's timestamp. We can groupby and get first of each (we make the assumption that the data is in chronological order).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_from_each_requestuuid = merged_requests[merged_requests.groupby('request_uuid')['timestamp'].rank() == 1 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130915"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_from_each_requestuuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many removed?\n",
    "\n",
    "Before: 2997586 After: 130915\n",
    "Decrease of 95.63265240763735%\n",
    "\n",
    "We see that there are A LOT of duplicates based already only on request_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2997586 After: 130915\n",
      "Decrease of 95.63265240763735%\n"
     ]
    }
   ],
   "source": [
    "before_count = len(merged_requests)\n",
    "after_count =  len(first_from_each_requestuuid)\n",
    "\n",
    "print(\"Before:\", before_count, \"After:\", after_count)\n",
    "print(\"Decrease of {}%\".format((100-(after_count/before_count)*100)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Saving data frame (without duplicates by requestuuid)\n",
    "\n",
    "first_from_each_requestuuid.to_csv(\"rate_quote_1_dup1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 - Removing extra duplicates - different request_uuid, but other parameters same (nearby timestamp) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
